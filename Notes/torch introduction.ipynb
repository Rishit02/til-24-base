{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.2+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torchvision in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.17.2+cpu)\n",
      "Requirement already satisfied: numpy in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (2.2.2+cpu)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2->torchvision) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch==2.2.2->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bsiva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "tensor([1, 2, 3, 4, 5], dtype=torch.int32)\n",
      "tensor([[0.4377, 0.7019, 0.4234],\n",
      "        [0.9541, 0.1530, 0.6634],\n",
      "        [0.6265, 0.4865, 0.3233]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "tensor2 = torch.from_numpy(np.array([1, 2, 3, 4, 5]))\n",
    "tensor3 = torch.rand((3, 3))\n",
    "\n",
    "print(tensor)\n",
    "print(tensor2)\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Automatic Differentiation is done with autograd\n",
    "x = torch.ones((2, 2), requires_grad=True) # requires_grad=True means that we want to compute the gradient of x\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "\n",
    "out = z.mean()\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module): # nn.Module is the base class for all models in PyTorch, and we need to inherit from it\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256) # 28x28 = 784 = num of pixels (input), 256 = num of neurons in the hidden layer; the one we choose\n",
    "        self.fc2 = nn.Linear(256, 128) # 256 = num of neurons in the hidden layer; the one we choose, 128 = num of neurons in the hidden layer; the one we choose\n",
    "        self.fc3 = nn.Linear(128, 10) # 128 = num of neurons in the hidden layer; the one we choose, 10 = num of classes (output)\n",
    "        # The number of layers can be change, but the input and output layers must be the same\n",
    "        # The psude output of one layer will have the same number of neurons as the input of the next layer\n",
    "\n",
    "    def forward(self, x): # This method defines the forward pass of the network, makes it pass through the layers\n",
    "        x = F.relu(self.fc1(x)) # ReLU is the activation function, it is used to introduce non-linearity to the network\n",
    "        x = F.relu(self.fc2(x)) # ReLU is rectified linear unit function, which takes the maximum of 0 and the input, therefore only outputs positive values\n",
    "        x = self.fc3(x) # Acticvation function takes in one value and outputs anoter\n",
    "        return x # Have many activation functions, but ReLU is the most common\n",
    "\n",
    "model = MLP()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "criterion = nn.CrossEntropyLoss() # Loss function, used to measure the difference between the predicted and the actual values\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Optimizer, used to update the weights of the network; Adam is the most common optimizer as it is more efficient than the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms # MNIST dataset is prebuilt in PyTorch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset: 28x28 images of handwritten digits from 0 to 9\n",
    "tansform = transforms.Compose([transforms.ToTensor()]) # Transform the images to tensors, as PyTorch works with tensors not images\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=tansform) # Load the training set\n",
    "# the transform parameter is used to transform the images to tensors, defined above\n",
    "\n",
    "# Load the test set\n",
    "image, label = mnist_trainset[0] #image is the image of the number which is a 28x28 tensor, label is the number itself\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.051379404962062836\n",
      "Epoch 2/10, Loss: 0.05472444370388985\n",
      "Epoch 3/10, Loss: 0.017733203247189522\n",
      "Epoch 4/10, Loss: 0.21691831946372986\n",
      "Epoch 5/10, Loss: 0.0049329414032399654\n",
      "Epoch 6/10, Loss: 0.07644681632518768\n",
      "Epoch 7/10, Loss: 0.0006050391239114106\n",
      "Epoch 8/10, Loss: 0.060720160603523254\n",
      "Epoch 9/10, Loss: 0.001087200129404664\n",
      "Epoch 10/10, Loss: 0.020603839308023453\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data transformation and loading\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(mnist_trainset, batch_size=64, shuffle=True) # DataLoader is used to load the data in batches, shuffle=True means that the data will be shuffled before loading\n",
    "# batching is used to speed up the training process, as it is faster to train on a batch of data than on the whole dataset\n",
    "\n",
    "# Training loop, one loop is called an epoch\n",
    "epcohs = 10\n",
    "for epoch in range(epcohs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        input = inputs.view(-1, 28*28) # Flatten the input images to a vector\n",
    "        optimizer.zero_grad() # Zero the gradients on every backpropagation ----> this is important\n",
    "        output = model(input) # given the input, the model will output the predicted values\n",
    "        loss = criterion(output, labels) # calculate the loss\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update the weights (Adam optimizer is used here)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epcohs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.97%\n"
     ]
    }
   ],
   "source": [
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform) # Load the test set, by train=False\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "def calculate_accuracy(model, loader):\n",
    "    model.eval() # set the model to evaluation mode, no more weights updates\n",
    "    total = correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader: # loop through the test set in batches\n",
    "            inputs = inputs.view(-1, 28*28) # flatten the input images\n",
    "            outputs = model(inputs) # get the predicted values = probabilities for each class\n",
    "            _, predicted = torch.max(outputs, 1) # get the predicted class\n",
    "            total += labels.size(0) # total number of labels\n",
    "            correct += (predicted == labels).sum().item() # number of correct predictions, checked against the actual labels in loader\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "accurcy = calculate_accuracy(model, testloader)\n",
    "print(f'Accuracy: {accurcy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.dropout = nn.Dropout(0.2) # Dropout is a regularization technique used to prevent overfitting\n",
    "# Each trianing iteration, a random set of neurons are dropped out, meaning that they are not used in the forward and backward pass\n",
    "# this forces the network to learn more robust features, as it cannot rely on the same neurons all the time\n",
    "# The dropout rate is the probability of dropping out a neuron, usually between 0.2 and 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 1.5126396148824997\n",
      "Epoch 2/25, Loss: 1.3020354915402337\n",
      "Epoch 3/25, Loss: 1.3055342716067584\n",
      "Epoch 4/25, Loss: 1.057545487242721\n",
      "Epoch 5/25, Loss: 0.8778234745330139\n",
      "Epoch 6/25, Loss: 0.8214235992383346\n",
      "Epoch 7/25, Loss: 0.9692026169251785\n",
      "Epoch 8/25, Loss: 0.7628819005829948\n",
      "Epoch 9/25, Loss: 0.6976475638113042\n",
      "Epoch 10/25, Loss: 0.6054678109885533\n",
      "Epoch 11/25, Loss: 0.5880031196245634\n",
      "Epoch 12/25, Loss: 0.4925762576493881\n",
      "Epoch 13/25, Loss: 0.5306714294847649\n",
      "Epoch 14/25, Loss: 0.5075141156930277\n",
      "Epoch 15/25, Loss: 0.5320630453066277\n",
      "Epoch 16/25, Loss: 0.5235460406935799\n",
      "Epoch 17/25, Loss: 0.5105780136864831\n",
      "Epoch 18/25, Loss: 0.5206768653238378\n",
      "Epoch 19/25, Loss: 0.47896728937083216\n",
      "Epoch 20/25, Loss: 0.5477826265590404\n",
      "Epoch 21/25, Loss: 0.5804685233339572\n",
      "Epoch 22/25, Loss: 0.6911037347908976\n",
      "Epoch 23/25, Loss: 0.7409774065812005\n",
      "Epoch 24/25, Loss: 0.8312561752826675\n",
      "Epoch 25/25, Loss: 0.7636924993826636\n",
      "Accuracy: 80.01%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 512)\n",
    "        self.fc6 = nn.Linear(512, 512)\n",
    "        self.fc7 = nn.Linear(512, 512)\n",
    "        self.fc8 = nn.Linear(512, 512)\n",
    "        self.fc9 = nn.Linear(512, 512)\n",
    "        self.fc10 = nn.Linear(512, 512)\n",
    "        self.fc11 = nn.Linear(512, 512)\n",
    "        self.fc12 = nn.Linear(512, 512)\n",
    "        self.fc13 = nn.Linear(512, 512)\n",
    "        self.fc14 = nn.Linear(512, 512)\n",
    "        self.fc15 = nn.Linear(512, 512)\n",
    "        self.fc16 = nn.Linear(512, 512)\n",
    "        self.fc17 = nn.Linear(512, 512)\n",
    "        self.fc18 = nn.Linear(512, 512)\n",
    "        self.fc19 = nn.Linear(512, 512)\n",
    "        self.fc20 = nn.Linear(512, 10)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc9(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc10(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc11(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc12(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc13(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc16(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc17(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc18(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc19(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc20(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "import torch\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.view(-1, 28*28)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader)}')\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "def calculate_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.view(-1, 28*28)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "accuracy = calculate_accuracy(model, testloader)\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 2.300757894765085\n",
      "Epoch 2/25, Loss: 1.9251194573414605\n",
      "Epoch 3/25, Loss: 1.3234803150457615\n",
      "Epoch 4/25, Loss: 1.2662203519710347\n",
      "Epoch 5/25, Loss: 1.0838254706056387\n",
      "Epoch 6/25, Loss: 0.9625076888593783\n",
      "Epoch 7/25, Loss: 0.8446106608234235\n",
      "Epoch 8/25, Loss: 1.2405749235326038\n",
      "Epoch 9/25, Loss: 0.8114790470996646\n",
      "Epoch 10/25, Loss: 0.8047132861576101\n",
      "Epoch 11/25, Loss: 0.7888777113037069\n",
      "Epoch 12/25, Loss: 0.6126897650550424\n",
      "Epoch 13/25, Loss: 0.5685630135698867\n",
      "Epoch 14/25, Loss: 0.538674927819004\n",
      "Epoch 15/25, Loss: 0.5160110651461809\n",
      "Epoch 16/25, Loss: 0.4863608401975652\n",
      "Epoch 17/25, Loss: 0.46719648882842013\n",
      "Epoch 18/25, Loss: 0.4392116416269528\n",
      "Epoch 19/25, Loss: 0.41799395828485997\n",
      "Epoch 20/25, Loss: 0.40262731115446926\n",
      "Epoch 21/25, Loss: 0.38418888663654643\n",
      "Epoch 22/25, Loss: 0.3865060942418286\n",
      "Epoch 23/25, Loss: 0.38423107656588684\n",
      "Epoch 24/25, Loss: 0.3716441736435458\n",
      "Epoch 25/25, Loss: 0.3720252524767476\n",
      "Accuracy: 45.74%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(512, 512)\n",
    "        self.dropout5 = nn.Dropout(0.3)\n",
    "        self.fc6 = nn.Linear(512, 512)\n",
    "        self.dropout6 = nn.Dropout(0.3)\n",
    "        self.fc7 = nn.Linear(512, 512)\n",
    "        self.dropout7 = nn.Dropout(0.3)\n",
    "        self.fc8 = nn.Linear(512, 512)\n",
    "        self.dropout8 = nn.Dropout(0.3)\n",
    "        self.fc9 = nn.Linear(512, 512)\n",
    "        self.dropout9 = nn.Dropout(0.3)\n",
    "        self.fc10 = nn.Linear(512, 512)\n",
    "        self.dropout10 = nn.Dropout(0.3)\n",
    "        self.fc11 = nn.Linear(512, 512)\n",
    "        self.dropout11 = nn.Dropout(0.3)\n",
    "        self.fc12 = nn.Linear(512, 512)\n",
    "        self.dropout12 = nn.Dropout(0.3)\n",
    "        self.fc13 = nn.Linear(512, 512)\n",
    "        self.dropout13 = nn.Dropout(0.3)\n",
    "        self.fc14 = nn.Linear(512, 512)\n",
    "        self.dropout14 = nn.Dropout(0.3)\n",
    "        self.fc15 = nn.Linear(512, 512)\n",
    "        self.dropout15 = nn.Dropout(0.3)\n",
    "        self.fc16 = nn.Linear(512, 512)\n",
    "        self.dropout16 = nn.Dropout(0.3)\n",
    "        self.fc17 = nn.Linear(512, 512)\n",
    "        self.dropout17 = nn.Dropout(0.3)\n",
    "        self.fc18 = nn.Linear(512, 512)\n",
    "        self.dropout18 = nn.Dropout(0.3)\n",
    "        self.fc19 = nn.Linear(512, 512)\n",
    "        self.dropout19 = nn.Dropout(0.3)\n",
    "        self.fc20 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.dropout6(x)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.dropout7(x)\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = self.dropout8(x)\n",
    "        x = F.relu(self.fc9(x))\n",
    "        x = self.dropout9(x)\n",
    "        x = F.relu(self.fc10(x))\n",
    "        x = self.dropout10(x)\n",
    "        x = F.relu(self.fc11(x))\n",
    "        x = self.dropout11(x)\n",
    "        x = F.relu(self.fc12(x))\n",
    "        x = self.dropout12(x)\n",
    "        x = F.relu(self.fc13(x))\n",
    "        x = self.dropout13(x)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.dropout14(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.dropout15(x)\n",
    "        x = F.relu(self.fc16(x))\n",
    "        x = self.dropout16(x)\n",
    "        x = F.relu(self.fc17(x))\n",
    "        x = self.dropout17(x)\n",
    "        x = F.relu(self.fc18(x))\n",
    "        x = self.dropout18(x)\n",
    "        x = F.relu(self.fc19(x))\n",
    "        x = self.dropout19(x)\n",
    "        x = self.fc20(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Decay LR by 0.1 every 10 epochs\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "epochs = 25\n",
    "patience = 10  # Number of epochs to wait before early stopping\n",
    "best_loss = float('inf')\n",
    "early_stop_count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.view(-1, 28*28)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}')\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        early_stop_count = 0\n",
    "        best_model_state = model.state_dict()  # Save the best model state\n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "        if early_stop_count >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "# Load the best model state\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "def calculate_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.view(-1, 28*28)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "accuracy = calculate_accuracy(model, testloader)\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.25980983799232094\n",
      "Epoch 2/30, Loss: 0.11505023592205317\n",
      "Epoch 3/30, Loss: 0.08424669247406569\n",
      "Epoch 4/30, Loss: 0.0700625877048987\n",
      "Epoch 5/30, Loss: 0.05702202471751553\n",
      "Epoch 6/30, Loss: 0.050390784414226945\n",
      "Epoch 7/30, Loss: 0.04695739888691349\n",
      "Epoch 8/30, Loss: 0.04116162037137332\n",
      "Epoch 9/30, Loss: 0.03539954930363195\n",
      "Epoch 10/30, Loss: 0.034517317237372176\n",
      "Epoch 11/30, Loss: 0.031698103229612556\n",
      "Epoch 12/30, Loss: 0.028647250911992377\n",
      "Epoch 13/30, Loss: 0.026591236675048927\n",
      "Epoch 14/30, Loss: 0.023878818227430938\n",
      "Epoch 15/30, Loss: 0.024980946857882325\n",
      "Epoch 16/30, Loss: 0.023911134309337924\n",
      "Epoch 17/30, Loss: 0.019307741735464158\n",
      "Epoch 18/30, Loss: 0.020245982284559857\n",
      "Epoch 19/30, Loss: 0.017178252481779496\n",
      "Epoch 20/30, Loss: 0.01862286256009669\n",
      "Epoch 21/30, Loss: 0.016783498484628408\n",
      "Epoch 22/30, Loss: 0.015136679182721944\n",
      "Epoch 23/30, Loss: 0.017004804825273726\n",
      "Epoch 24/30, Loss: 0.015969918871078508\n",
      "Epoch 25/30, Loss: 0.016583392421763613\n",
      "Epoch 26/30, Loss: 0.014330353592426877\n",
      "Epoch 27/30, Loss: 0.012703251737199212\n",
      "Epoch 28/30, Loss: 0.01278278335615787\n",
      "Epoch 29/30, Loss: 0.01335795061123969\n",
      "Epoch 30/30, Loss: 0.013096876630831613\n",
      "Accuracy: 98.28%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)  # Add batch normalization\n",
    "        self.dropout1 = nn.Dropout(0.2)  # Adjust dropout rate\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the input tensor\n",
    "        x = F.relu(self.bn1(self.fc1(x)))  # Apply batch normalization and ReLU\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize the data\n",
    "])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(mnist_trainset, batch_size=128, shuffle=True)  # Increase batch size\n",
    "\n",
    "epochs = 30  # Increase the number of epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader)}')\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "def calculate_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "accuracy = calculate_accuracy(model, testloader)\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here are the changes made to the original model:\n",
    "\n",
    "Batch Normalization: Added batch normalization layers (nn.BatchNorm1d) after each linear layer to help stabilize the training process and allow for higher learning rates.\n",
    "Dropout Rate: Reduced the dropout rate from 0.3 to 0.2 to prevent too much information loss during training.\n",
    "Model Architecture: Adjusted the number of neurons in the hidden layers to (512, 256, 128) instead of (256, 128) to increase the model's capacity.\n",
    "Data Normalization: Normalized the input data using the mean and standard deviation of the MNIST dataset (transforms.Normalize).\n",
    "Batch Size: Increased the batch size from 64 to 128 for faster convergence.\n",
    "Number of Epochs: Increased the number of training epochs from 10 to 30 to allow the model to train for longer.\n",
    "Optimizer: Kept the Adam optimizer with a learning rate of 0.001.\n",
    "\n",
    "To get the mean and standard deviation values for transforms.Normalize, you can calculate them from the dataset itself or use the pre-computed values for popular datasets like MNIST.\n",
    "For the MNIST dataset, the mean and standard deviation values of (0.1307) and (0.3081) are widely used and accepted. These values were calculated by computing the mean and standard deviation of the pixel values across the entire MNIST training dataset.\n",
    "If you're working with a different dataset, you can calculate the mean and standard deviation of the pixel values (or any other input features) using the following steps:\n",
    "\n",
    "Load the dataset (or a subset of it) into memory.\n",
    "Flatten the input data (e.g., for images, convert them to 1D vectors).\n",
    "Calculate the mean and standard deviation across all examples using NumPy or PyTorch functions:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.YourDataset(...)\n",
    "\n",
    "# Flatten the input data\n",
    "data = np.concatenate([np.array(x).flatten() for x, _ in dataset])\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(data)\n",
    "std = np.std(data)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "As for batch normalization, it is a widely used and effective technique in deep learning, but it doesn't always work equally well for all tasks or architectures. Here are some general guidelines on when batch normalization can be useful:\n",
    "\n",
    "Deep Networks: Batch normalization is particularly helpful in deep neural networks (e.g., networks with more than 5-10 layers) as it helps mitigate the internal covariate shift and stabilize the training process.\n",
    "Convolutional Neural Networks (CNNs): Batch normalization is commonly used in CNNs, as it can help accelerate the training of convolutional layers and improve the model's performance.\n",
    "Recurrent Neural Networks (RNNs): Batch normalization has been shown to improve the training of RNNs, especially for longer sequences.\n",
    "Non-Linear Activations: Batch normalization can be beneficial when using non-linear activation functions like ReLU, which can cause the gradients to become unstable or vanish during backpropagation.\n",
    "\n",
    "However, there are cases where batch normalization may not be as effective or necessary:\n",
    "\n",
    "Shallow Networks: In very shallow networks (e.g., 2-3 layers), batch normalization may not provide significant benefits, as the internal covariate shift is less severe.\n",
    "Normalizing Inputs: If your input data is already well-normalized or standardized, batch normalization may have a less significant impact.\n",
    "Small Batch Sizes: Batch normalization relies on computing statistics (mean and variance) over mini-batches. With very small batch sizes, these statistics may become noisy and less reliable, potentially hindering the benefits of batch normalization.\n",
    "Certain Architectures: Some architectures, like ResNets or DenseNets, may already have built-in mechanisms (e.g., skip connections) that help mitigate the internal covariate shift, reducing the need for batch normalization.\n",
    "\n",
    "A common approach is to start with a reasonable number of buckets (e.g., 10-20) and adjust based on the results:\n",
    "\n",
    "    If buckets are too small (many empty or low-count buckets), increase the size.\n",
    "    If buckets are too large (hiding important patterns), decrease the size.\n",
    "\n",
    "Some formulas can serve as starting points:\n",
    "\n",
    "    Square-root choice: Bucket count = sqrt(n), where n is the number of data points.\n",
    "    Sturges' formula: Bucket count = log2(n) + 1\n",
    "    Rice rule: Bucket count = 2 * cube_root(n)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
